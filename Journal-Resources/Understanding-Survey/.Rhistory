# set color scale for versions
scale_color_manual(values = c("#0077dd", "#dd1100")) +
# set scale for y axis
ylim(0.00, 1.00) +
# add median with special color
stat_summary(fun = "median", geom = "point", shape = 16, size = 8, color = "#ffa600d8") +
labs(x = "Treatment", y = "TAU") +
theme(
text = element_text(size = 12, face = "bold", family = "sans"),
axis.title = element_text(size = 14),
axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 10),
legend.position = "none"
)
# start hypothesis testing
# due to multiple hypotheses, we will use the Holm-Bonferroni correction to adjust the computed p-values; the confidence level is therefore set to 0.05 here
confLevel <- 0.05
# calculate Wilcoxon–Mann–Whitney test
# standard implementation from the `stats` package (asymptotic approximation with ties)
# for individual rules
testResults <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varTAUP <- paste("TAU", p, sep = "_")
varTAUAP <- paste("TAU", ap, sep = "_")
w <- wilcox.test(
x = data[[varTAUP]],
y = data[[varTAUAP]],
alternative = "greater",
conf.level = confLevel
)
# calculate the effect size with Cohens d
d <- cohens_d(data[[varTAUP]], data[[varTAUAP]])
# create results data frame
rule <- c(p)
U.value <- c(w$statistic)
p.value <- c(w$p.value)
cohens.d <- c(d$Cohens_d)
testResults <- rbind(testResults,
data.frame(rule, U.value, p.value, cohens.d),
make.row.names = FALSE
)
}
print(testResults)
# adjust p-values with Holm-Bonferroni and format them
testResults <- testResults %>%
mutate(p.value = format.pval(
p.adjust(p.value, method = "holm"),
digits = 4, eps = 0.001
)
)
print(testResults)
# for all rules combined
w <- wilcox.test(
x = combinedDf$Pattern_TAU,
y = combinedDf$Antipattern_TAU,
alternative = "greater",
conf.level = confLevel
)
d <- cohens_d(combinedDf$Pattern_TAU, combinedDf$Antipattern_TAU)
rule <- c("All rules combined")
U.value <- c(w$statistic)
p.value <- c(format.pval(w$p.value, digits = 4, eps = 0.001))
cohens.d <- c(d$Cohens_d)
testResults <- rbind(testResults,
data.frame(rule, U.value, p.value, cohens.d),
make.row.names = FALSE
)
print(testResults)
# visualize d values with bar plot
barplotData <- testResults %>%
filter(rule != "All rules combined")
# use ggplot to print the bar chart
ggplot(barplotData, aes(x = reorder(rule, cohens.d), y = cohens.d)) +
geom_bar(
stat = "identity",
width = 0.8,
fill = "#0077dd"
) +
# control space for the labels
scale_y_continuous(expand = expansion(mult = c(0, .1))) +
# bar label text and positioning
geom_text(
aes(label = sprintf("%.2f", round(cohens.d, 2))),
size = 5.1,
fontface = "bold",
hjust = -0.05
) +
theme_classic() +
labs(x = "Rule", y = "Cohen's d") +
theme(
text = element_text(size = 16, face = "bold", family = "sans"),
axis.title = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.text.y = element_text(size = 14),
legend.title = element_text(size = 16),
legend.text = element_text(size = 16)
) +
# flip the chart horizontally
coord_flip()
# calculate descriptive statistics for perceived understandability ratings
descriptiveStats <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varTAUP <- as.name(paste("TAU", p, sep = "_"))
varTAUAP <- as.name(paste("TAU", ap, sep = "_"))
varP <- as.name(paste(varP, "", sep = ""))
varAP <- as.name(paste(varAP, "", sep = ""))
varP_rating <- as.name(paste(varP, "URating", sep = ""))
varAp_rating <- as.name(paste(varAP, "URating", sep = ""))
descriptiveStats <- rbind(
descriptiveStats,
data %>% summarise(
rule = var,
median_rating_P := median({{ varP_rating }}, na.rm = TRUE),
median_rating_AP := median({{ varAP_rating }}, na.rm = TRUE),
mean_rating_P := round(mean({{ varP_rating }}, na.rm = TRUE), 2),
mean_rating_AP := round(mean({{ varAP_rating }}, na.rm = TRUE), 2),
mean_TAU_P := mean({{ varTAUP }}, na.rm = TRUE),
mean_TAU_AP := mean({{ varTAUAP }}, na.rm = TRUE),
correctPercent_P := scales::percent(sum({{ varP }}, na.rm = TRUE) / (data %>% filter(!is.na({{ varP }})) %>% nrow())),
correctPercent_AP := scales::percent(sum({{ varAP }}, na.rm = TRUE) / (data %>% filter(!is.na({{ varAP }})) %>% nrow()))
)
)
}
# calculate descriptive statistics for perceived understandability ratings
descriptiveStats <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varTAUP <- as.name(paste("TAU", p, sep = "_"))
varTAUAP <- as.name(paste("TAU", ap, sep = "_"))
varP <- as.name(paste(varP, "", sep = ""))
varAP <- as.name(paste(varAP, "", sep = ""))
varP_rating <- as.name(paste(varP, "URating", sep = ""))
varAP_rating <- as.name(paste(varAP, "URating", sep = ""))
descriptiveStats <- rbind(
descriptiveStats,
data %>% summarise(
rule = var,
median_rating_P := median({{ varP_rating }}, na.rm = TRUE),
median_rating_AP := median({{ varAP_rating }}, na.rm = TRUE),
mean_rating_P := round(mean({{ varP_rating }}, na.rm = TRUE), 2),
mean_rating_AP := round(mean({{ varAP_rating }}, na.rm = TRUE), 2),
mean_TAU_P := mean({{ varTAUP }}, na.rm = TRUE),
mean_TAU_AP := mean({{ varTAUAP }}, na.rm = TRUE),
correctPercent_P := scales::percent(sum({{ varP }}, na.rm = TRUE) / (data %>% filter(!is.na({{ varP }})) %>% nrow())),
correctPercent_AP := scales::percent(sum({{ varAP }}, na.rm = TRUE) / (data %>% filter(!is.na({{ varAP }})) %>% nrow()))
)
)
}
# calculate descriptive statistics for perceived understandability ratings
descriptiveStats <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varTAUP <- as.name(paste("TAU", p, sep = "_"))
varTAUAP <- as.name(paste("TAU", ap, sep = "_"))
varP <- as.name(paste(varP, "", sep = ""))
varAP <- as.name(paste(varAP, "", sep = ""))
varP_rating <- as.name(paste(varP, "URating", sep = ""))
varAP_rating <- as.name(paste(varAP, "URating", sep = ""))
descriptiveStats <- rbind(
descriptiveStats,
data %>% summarise(
median_rating_P := median({{ varP_rating }}, na.rm = TRUE),
median_rating_AP := median({{ varAP_rating }}, na.rm = TRUE),
mean_rating_P := round(mean({{ varP_rating }}, na.rm = TRUE), 2),
mean_rating_AP := round(mean({{ varAP_rating }}, na.rm = TRUE), 2),
mean_TAU_P := mean({{ varTAUP }}, na.rm = TRUE),
mean_TAU_AP := mean({{ varTAUAP }}, na.rm = TRUE),
correctPercent_P := scales::percent(sum({{ varP }}, na.rm = TRUE) / (data %>% filter(!is.na({{ varP }})) %>% nrow())),
correctPercent_AP := scales::percent(sum({{ varAP }}, na.rm = TRUE) / (data %>% filter(!is.na({{ varAP }})) %>% nrow()))
)
)
}
print(descriptiveStats)
# calculate descriptive statistics for perceived understandability ratings
descriptiveStats <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varTAUP <- as.name(paste("TAU", p, sep = "_"))
varTAUAP <- as.name(paste("TAU", ap, sep = "_"))
varP <- as.name(paste(varP, "", sep = ""))
varAP <- as.name(paste(varAP, "", sep = ""))
varP_rating <- as.name(paste(varP, "URating", sep = ""))
varAP_rating <- as.name(paste(varAP, "URating", sep = ""))
descriptiveStats <- rbind(
descriptiveStats,
data %>% summarise(
rule = p,
median_rating_P := median({{ varP_rating }}, na.rm = TRUE),
median_rating_AP := median({{ varAP_rating }}, na.rm = TRUE),
mean_rating_P := round(mean({{ varP_rating }}, na.rm = TRUE), 2),
mean_rating_AP := round(mean({{ varAP_rating }}, na.rm = TRUE), 2),
mean_TAU_P := mean({{ varTAUP }}, na.rm = TRUE),
mean_TAU_AP := mean({{ varTAUAP }}, na.rm = TRUE),
correctPercent_P := scales::percent(sum({{ varP }}, na.rm = TRUE) / (data %>% filter(!is.na({{ varP }})) %>% nrow())),
correctPercent_AP := scales::percent(sum({{ varAP }}, na.rm = TRUE) / (data %>% filter(!is.na({{ varAP }})) %>% nrow()))
)
)
}
print(descriptiveStats)
# calculate more detailed descriptive stats per individual rule (min, max, var)
descriptiveStatsDetails <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varP_rating <- as.name(paste(p, "URrating", sep = ""))
varAP_rating <- as.name(paste(ap, "URating", sep = ""))
descriptiveStatsDetails <- rbind(
descriptiveStatsDetails,
data %>% summarise(
rule = p,
min_rating_P := min({{ varP_rating }}, na.rm = TRUE),
min_rating_AP := min({{ varAP_rating }}, na.rm = TRUE),
max_rating_P := max({{ varP_rating }}, na.rm = TRUE),
max_rating_AP := max({{ varAP_rating }}, na.rm = TRUE),
var_rating_P := var({{ varP_rating }}, na.rm = TRUE),
var_rating_AP := var({{ varAP_rating }}, na.rm = TRUE)
)
)
}
# calculate more detailed descriptive stats per individual rule (min, max, var)
descriptiveStatsDetails <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varP_rating <- as.name(paste(p, "URating", sep = ""))
varAP_rating <- as.name(paste(ap, "URating", sep = ""))
descriptiveStatsDetails <- rbind(
descriptiveStatsDetails,
data %>% summarise(
rule = p,
min_rating_P := min({{ varP_rating }}, na.rm = TRUE),
min_rating_AP := min({{ varAP_rating }}, na.rm = TRUE),
max_rating_P := max({{ varP_rating }}, na.rm = TRUE),
max_rating_AP := max({{ varAP_rating }}, na.rm = TRUE),
var_rating_P := var({{ varP_rating }}, na.rm = TRUE),
var_rating_AP := var({{ varAP_rating }}, na.rm = TRUE)
)
)
}
print(descriptiveStatsDetails)
# create custom likert plots for perceived understandability ratings
ratings <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varRatingP <- as.name(paste(p, "URating", sep = ""))
varRatingAp <- as.name(paste(ap, "URating", sep = ""))
P1 <- data %>% filter({{ varRatingP }} == 1) %>% nrow() * -1
P2 <- data %>% filter({{ varRatingAP }} == 2) %>% nrow() * -1
AP1 <- data %>% filter({{ varRatingA }} == 1) %>% nrow()
AP2 <- data %>% filter({{ varRatingP }} == 2) %>% nrow()
ratings <- rbind(ratings,
data.frame(
rule = as.character(p),
countP1 = P1,
countP2 = P2,
countAP1 = AP1,
countAP2 = AP2
)
)
}
# create custom likert plots for perceived understandability ratings
ratings <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varRatingP <- as.name(paste(p, "URating", sep = ""))
varRatingAP <- as.name(paste(ap, "URating", sep = ""))
P1 <- data %>% filter({{ varRatingP }} == 1) %>% nrow() * -1
P2 <- data %>% filter({{ varRatingAP }} == 2) %>% nrow() * -1
AP1 <- data %>% filter({{ varRatingA }} == 1) %>% nrow()
AP2 <- data %>% filter({{ varRatingP }} == 2) %>% nrow()
ratings <- rbind(ratings,
data.frame(
rule = as.character(p),
countP1 = P1,
countP2 = P2,
countAP1 = AP1,
countAP2 = AP2
)
)
}
# create custom likert plots for perceived understandability ratings
ratings <- data.frame()
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varRatingP <- as.name(paste(p, "URating", sep = ""))
varRatingAP <- as.name(paste(ap, "URating", sep = ""))
P1 <- data %>% filter({{ varRatingP }} == 1) %>% nrow() * -1
P2 <- data %>% filter({{ varRatingP }} == 2) %>% nrow() * -1
AP1 <- data %>% filter({{ varRatingAP }} == 1) %>% nrow()
AP2 <- data %>% filter({{ varRatingAP }} == 2) %>% nrow()
ratings <- rbind(ratings,
data.frame(
rule = as.character(p),
countP1 = P1,
countP2 = P2,
countAP1 = AP1,
countAP2 = AP2
)
)
}
print(ratings)
# melt the data frame into long format and create factor for ratings
ratings_long <- reshape2::melt(ratings, id.vars = "rule")
ratings_long$variable <- factor(
ratings_long$variable,
levels = c("countP1", "countP2", "countAP1", "countAP2"),
labels = c("Very easy (pattern)", "Easy (pattern)", "Very easy (antipattern)", "Easy (antipattern)")
)
print(ratings_long)
# order according to categories
ratings_long <- ratings_long %>%
arrange(factor(rule, levels = rev(ruleNames))) %>%
mutate(index = row_number())
# order according to categories
ratings_long <- ratings_long %>%
arrange(factor(rule, levels = rev(p))) %>%
mutate(index = row_number())
print(ratings_long)
# create break values to avoid negative numbers
break_values <- append(pretty(ratings_long$value), c(30, 40, 50))
# create the plot
ggplot(ratings_long, aes(x = reorder(rule, index), y = value, fill = variable)) +
geom_bar(stat = "identity") +
theme_classic() +
# hide y axis
theme(
axis.line.y = element_blank(),
axis.ticks.y = element_blank()
) +
labs(x = "Rule", y = "# of ratings per difficulty level", fill = "") +
# set absolute numbers to avoid negatives and stretch axis the same in both directions
scale_y_continuous(
limits = c(-51, 51),
breaks = break_values,
labels = abs(break_values)
) +
# colors for the 4 counts
scale_fill_manual(values = c("#0077dd", "lightblue", "#dd1100", "#ff7e73")) +
# bar label text and positioning
geom_text(
aes(label = abs(value)),
position = position_stack(vjust = 0.5),
fontface = "bold",
size = 5.5,
color = "white"
) +
# add vertical line in the middle
geom_hline(yintercept = 0, size = 0.75) +
theme(
text = element_text(size = 16, face = "bold", family = "sans"),
axis.title = element_text(size = 18),
axis.text.x = element_text(size = 16),
axis.text.y = element_text(size = 16),
legend.text = element_text(size = 16),
legend.position = "top"
) +
# flip the chart horizontally
coord_flip()
# start hypothesis testing
# due to multiple hypotheses, we will use the Holm-Bonferroni correction to adjust the computed p-values; the confidence level is therefore set to 0.05 here
confLevel <- 0.05
# calculate Wilcoxon–Mann–Whitney test
# standard implementation from the `stats` package (asymptotic approximation with ties)
testResults <- data.frame()
# for individual rules
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varRatingP <- paste(p, "URating", sep = "")
varRatingAP <- paste(ap, "URating", sep = "")
w <- wilcox.test(
x = data[[varRatingAP]],
y = data[[varRatingP]],
alternative = "greater",
conf.level = confLevel
)
# calculate the effect size with Cohens d
d <- cohens_d(data[[varRatingAP]], data[[varRatingP]])
# create results data frame
rule <- c(p)
U.value <- c(w$statistic)
p.value <- c(w$p.value)
cohens.d <- c(d$Cohens_d)
testResults <- rbind(testResults,
data.frame(rule, U.value, p.value, cohens.d),
make.row.names = FALSE
)
}
print(testResults)
# adjust p-values with Holm-Bonferroni and format them
testResults <- testResults %>%
mutate(p.value = format.pval(
p.adjust(p.value, method = "holm"),
digits = 4, eps = 0.001
)
)
# for all rules combined
w <- wilcox.test(
x = combinedDf$IR_rating,
y = combinedDf$FR_rating,
alternative = "greater",
conf.level = confLevel
)
# for individual rules
for (i in seq_along(patterns)) {
p <- patterns[i]
ap <- antipatterns[i]
varRatingP <- paste(p, "URating", sep = "")
varRatingAP <- paste(ap, "URating", sep = "")
w <- wilcox.test(
x = data[[varRatingAP]],
y = data[[varRatingP]],
alternative = "greater",
conf.level = confLevel
)
# calculate the effect size with Cohens d
d <- cohens_d(data[[varRatingAP]], data[[varRatingP]])
# create results data frame
rule <- c(p)
U.value <- c(w$statistic)
p.value <- c(w$p.value)
cohens.d <- c(d$Cohens_d)
testResults <- rbind(testResults,
data.frame(rule, U.value, p.value, cohens.d),
make.row.names = FALSE
)
}
print(testResults)
# adjust p-values with Holm-Bonferroni and format them
testResults <- testResults %>%
mutate(p.value = format.pval(
p.adjust(p.value, method = "holm"),
digits = 4, eps = 0.001
)
)
print(testResults)
# for all rules combined
w <- wilcox.test(
x = combinedDf$IR_rating,
y = combinedDf$FR_rating,
alternative = "greater",
conf.level = confLevel
)
print(combinedDf)
# for all rules combined
w <- wilcox.test(
x = combinedDf$Pattern_rating,
y = combinedDf$Antipattern_rating,
alternative = "greater",
conf.level = confLevel
)
d <- cohens_d(combinedDf$IR_rating, combinedDf$FR_rating)
# for all rules combined
w <- wilcox.test(
x = combinedDf$Pattern_rating,
y = combinedDf$Antipattern_rating,
alternative = "greater",
conf.level = confLevel
)
d <- cohens_d(combinedDf$Pattern_rating, combinedDf$Antipattern_rating)
rule <- c("All rules combined")
U.value <- c(w$statistic)
p.value <- c(format.pval(w$p.value, digits = 4, eps = 0.001))
cohens.d <- c(d$Cohens_d)
testResults <- rbind(testResults,
data.frame(rule, U.value, p.value, cohens.d),
make.row.names = FALSE
)
print(testResults)
# visualize d values with bar plot
barplotData <- testResults %>%
filter(rule != "All rules combined" & rule != "PathHierarchy3" &
rule != "VerbController" & rule != "RC415")
# use ggplot to print the bar chart
ggplot(barplotData, aes(x = reorder(rule, cohens.d), y = cohens.d)) +
geom_bar(
stat = "identity",
width = 0.8,
fill = "#0077dd"
) +
# control space for the labels
scale_y_continuous(expand = expansion(mult = c(0, .1))) +
# bar label text and positioning
geom_text(
aes(label = sprintf("%.2f", round(cohens.d, 2))),
size = 5.1,
fontface = "bold",
hjust = -0.05
) +
theme_classic() +
labs(x = "Rule", y = "Cohen's d") +
theme(
text = element_text(size = 16, face = "bold", family = "sans"),
axis.title = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.text.y = element_text(size = 14),
legend.title = element_text(size = 16),
legend.text = element_text(size = 16)
) +
# flip the chart horizontally
coord_flip()
print(testResults)
